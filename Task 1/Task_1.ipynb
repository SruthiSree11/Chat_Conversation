{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4de61e4-eab8-412f-9871-fceaaa3b8be4",
   "metadata": {},
   "source": [
    "# Conversation History Management & Summarization System\n",
    "\n",
    "## Project Description\n",
    "This notebook demonstrates a robust system for **managing conversational chat history** between a user and an assistant. The system allows:\n",
    "\n",
    "- **Maintaining a running conversation history** of userâ€“assistant interactions.  \n",
    "- **Summarizing conversation history** to keep it concise while preserving important context.  \n",
    "- **Customizable truncation** to control the size of conversation history:\n",
    "  - By **number of conversation turns** (e.g., last n messages).  \n",
    "  - By **total word count** or **character length**.  \n",
    "- **Periodic summarization** after every k-th turn of conversation, replacing previous messages with a concise summary for efficient memory management.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b1e03f-c38e-434a-8866-ab19502af43d",
   "metadata": {},
   "source": [
    "## Initialize Groq client (OpenAI SDK compatible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc4ad1b-fdb5-40a6-b7f5-4493488e3e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "client = Groq(api_key=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2dea5-6782-4970-bb39-22b6f90c666a",
   "metadata": {},
   "source": [
    "## Defining Core Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cda1fb-f981-4c01-a03f-41e03b12ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationManager:\n",
    "    def __init__(self, max_turns=None, max_words=None):\n",
    "        self.history = []\n",
    "        self.run_count = 0\n",
    "        self.max_turns = max_turns\n",
    "        self.max_words = max_words\n",
    "    \n",
    "    def add_message(self, role, content):\n",
    "        \"\"\"Add a message and apply truncation rules\"\"\"\n",
    "        self.history.append({\"role\": role, \"content\": content})\n",
    "        self.run_count += 1\n",
    "        self.apply_truncation()\n",
    "    \n",
    "    def apply_truncation(self):\n",
    "        \"\"\"Apply turn-based and word-length truncation\"\"\"\n",
    "        # Turn-based truncation (keep last n turns)\n",
    "        if self.max_turns:\n",
    "            self.history = self.history[-self.max_turns:]\n",
    "        \n",
    "        # Word-length truncation\n",
    "        if self.max_words:\n",
    "            total_words = sum(len(m['content'].split()) for m in self.history)\n",
    "            while total_words > self.max_words and self.history:\n",
    "                removed = self.history.pop(0)\n",
    "                total_words -= len(removed['content'].split())\n",
    "    \n",
    "    def summarize_history(self, client, model=\"llama-3.1-8b-instant\"):\n",
    "        \"\"\"Summarize conversation history\"\"\"\n",
    "        if not self.history:\n",
    "            return\n",
    "        \n",
    "        conv_text = \"\\n\".join([f\"{m['role'].capitalize()}: {m['content']}\" for m in self.history])\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Summarize this conversation concisely in 2-3 sentences:\"},\n",
    "                    {\"role\": \"user\", \"content\": conv_text}\n",
    "                ],\n",
    "                max_tokens=100,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            summary = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Replace history with summary + keep last 2 exchanges for context\n",
    "            last_messages = self.history[-2:] if len(self.history) >= 2 else self.history\n",
    "            self.history = [{\"role\": \"system\", \"content\": f\"Previous conversation summary: {summary}\"}] + last_messages\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Summarization failed: {e}\")\n",
    "    \n",
    "    def periodic_summary(self, client, k=3, model=\"llama-3.1-8b-instant\"):\n",
    "        \"\"\"Perform summarization every k-th run\"\"\"\n",
    "        if self.run_count % k == 0 and self.run_count > 0:\n",
    "            print(f\"\\nðŸ”„ TRIGGERING PERIODIC SUMMARIZATION (Run #{self.run_count})\")\n",
    "            self.summarize_history(client, model=model)\n",
    "    \n",
    "    def get_readable_history(self):\n",
    "        \"\"\"Get formatted conversation history\"\"\"\n",
    "        return \"\\n\".join([f\"{m['role'].capitalize()}: {m['content']}\" for m in self.history])\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get conversation statistics\"\"\"\n",
    "        total_words = sum(len(m['content'].split()) for m in self.history)\n",
    "        return {\n",
    "            \"turns\": len(self.history),\n",
    "            \"total_words\": total_words,\n",
    "            \"run_count\": self.run_count\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9ca7b-6e53-45f5-958c-1a8e6cee0c62",
   "metadata": {},
   "source": [
    "## DEMO 1: Basic Functionality - Multiple Conversation Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "745338fe-a5dc-4353-8acd-4165d43ce199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DEMO 1: FEEDING MULTIPLE CONVERSATION SAMPLES\n",
      "============================================================\n",
      "ðŸ”¹ Conversation after feeding 6 messages (max_turns=5):\n",
      "Assistant: Hello Niharika! Nice to meet you. How are you today?\n",
      "User: I'm doing well, just finished my college classes.\n",
      "Assistant: That's great! What are you studying?\n",
      "User: I'm pursuing Computer Science Engineering.\n",
      "Assistant: Excellent choice! Are you interested in any specific area like AI or web development?\n",
      "\n",
      "Stats: {'turns': 5, 'total_words': 43, 'run_count': 6}\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DEMO 1: FEEDING MULTIPLE CONVERSATION SAMPLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "sample_chats = [\n",
    "    (\"user\", \"Hi, I'm Niharika from Guntur.\"),\n",
    "    (\"assistant\", \"Hello Niharika! Nice to meet you. How are you today?\"),\n",
    "    (\"user\", \"I'm doing well, just finished my college classes.\"),\n",
    "    (\"assistant\", \"That's great! What are you studying?\"),\n",
    "    (\"user\", \"I'm pursuing Computer Science Engineering.\"),\n",
    "    (\"assistant\", \"Excellent choice! Are you interested in any specific area like AI or web development?\")\n",
    "]\n",
    "\n",
    "cm1 = ConversationManager(max_turns=5)\n",
    "\n",
    "for role, msg in sample_chats:\n",
    "    cm1.add_message(role, msg)\n",
    "\n",
    "print(\"ðŸ”¹ Conversation after feeding 6 messages (max_turns=5):\")\n",
    "print(cm1.get_readable_history())\n",
    "print(f\"\\nStats: {cm1.get_stats()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293bc71-e350-403f-86c5-a49e9c7b0b67",
   "metadata": {},
   "source": [
    "## DEMO 2: Word-Length Truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8054aca0-9c03-4fee-8f3b-2f51c828b3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEMO 2: WORD-LENGTH TRUNCATION\n",
      "============================================================\n",
      "ðŸ”¹ Conversation after word-length truncation (25 words max):\n",
      "Assistant: That's great! What are you studying?\n",
      "User: I'm pursuing Computer Science Engineering.\n",
      "Assistant: Excellent choice! Are you interested in any specific area like AI or web development?\n",
      "\n",
      "Stats: {'turns': 3, 'total_words': 25, 'run_count': 6}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DEMO 2: WORD-LENGTH TRUNCATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cm2 = ConversationManager(max_words=25)\n",
    "\n",
    "for role, msg in sample_chats:\n",
    "    cm2.add_message(role, msg)\n",
    "\n",
    "print(\"ðŸ”¹ Conversation after word-length truncation (25 words max):\")\n",
    "print(cm2.get_readable_history())\n",
    "print(f\"\\nStats: {cm2.get_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7804e-ce1a-4afd-87ee-3dbe5dd5e5f2",
   "metadata": {},
   "source": [
    "## DEMO 3: Periodic Summarization (Every 3rd Run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6202b7c7-3ce8-4242-80d0-c7026353348c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEMO 3: PERIODIC SUMMARIZATION (Every 3rd Run)\n",
      "============================================================\n",
      "\n",
      "ðŸ”¸ After Run 1:\n",
      "User: Hello!\n",
      "Stats: {'turns': 1, 'total_words': 1, 'run_count': 1}\n",
      "\n",
      "ðŸ”¸ After Run 2:\n",
      "User: Hello!\n",
      "Assistant: Hi there! How can I help you?\n",
      "Stats: {'turns': 2, 'total_words': 8, 'run_count': 2}\n",
      "\n",
      "ðŸ”„ TRIGGERING PERIODIC SUMMARIZATION (Run #3)\n",
      "\n",
      "ðŸ”¸ After Run 3:\n",
      "System: Previous conversation summary: There is no conversation to summarize yet. I'll start one with you. \n",
      "\n",
      "You've expressed interest in learning Python programming. I can provide you with resources and guidance to get started. Would you like to know where to begin or have any specific questions about Python?\n",
      "Assistant: Hi there! How can I help you?\n",
      "User: I want to learn Python programming.\n",
      "Stats: {'turns': 3, 'total_words': 61, 'run_count': 3}\n",
      "\n",
      "ðŸ”¸ After Run 4:\n",
      "System: Previous conversation summary: There is no conversation to summarize yet. I'll start one with you. \n",
      "\n",
      "You've expressed interest in learning Python programming. I can provide you with resources and guidance to get started. Would you like to know where to begin or have any specific questions about Python?\n",
      "Assistant: Hi there! How can I help you?\n",
      "User: I want to learn Python programming.\n",
      "Assistant: Great choice! Python is beginner-friendly and versatile.\n",
      "Stats: {'turns': 4, 'total_words': 68, 'run_count': 4}\n",
      "\n",
      "ðŸ”¸ After Run 5:\n",
      "System: Previous conversation summary: There is no conversation to summarize yet. I'll start one with you. \n",
      "\n",
      "You've expressed interest in learning Python programming. I can provide you with resources and guidance to get started. Would you like to know where to begin or have any specific questions about Python?\n",
      "Assistant: Hi there! How can I help you?\n",
      "User: I want to learn Python programming.\n",
      "Assistant: Great choice! Python is beginner-friendly and versatile.\n",
      "User: Where should I start?\n",
      "Stats: {'turns': 5, 'total_words': 72, 'run_count': 5}\n",
      "\n",
      "ðŸ”„ TRIGGERING PERIODIC SUMMARIZATION (Run #6)\n",
      "\n",
      "ðŸ”¸ After Run 6:\n",
      "System: Previous conversation summary: There is no previous conversation to summarize. This conversation just started.\n",
      "User: Where should I start?\n",
      "Assistant: I'd recommend starting with basic syntax and data types.\n",
      "Stats: {'turns': 3, 'total_words': 27, 'run_count': 6}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DEMO 3: PERIODIC SUMMARIZATION (Every 3rd Run)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cm3 = ConversationManager(max_turns=10)\n",
    "\n",
    "short_chat = [\n",
    "    (\"user\", \"Hello!\"),\n",
    "    (\"assistant\", \"Hi there! How can I help you?\"),\n",
    "    (\"user\", \"I want to learn Python programming.\"),\n",
    "    (\"assistant\", \"Great choice! Python is beginner-friendly and versatile.\"),\n",
    "    (\"user\", \"Where should I start?\"),\n",
    "    (\"assistant\", \"I'd recommend starting with basic syntax and data types.\"),\n",
    "]\n",
    "\n",
    "for i, (role, msg) in enumerate(short_chat, start=1):\n",
    "    cm3.add_message(role, msg)\n",
    "    cm3.periodic_summary(client, k=3)\n",
    "    \n",
    "    print(f\"\\nðŸ”¸ After Run {i}:\")\n",
    "    print(cm3.get_readable_history())\n",
    "    print(f\"Stats: {cm3.get_stats()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37600150-396a-4310-b46c-2dd2eb4de6ea",
   "metadata": {},
   "source": [
    "## DEMO 4: COMPREHENSIVE LONG CONVERSATION (15 Turns)\n",
    "# Shows all functionalities working together in a realistic scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1ad904-81d9-4ac9-a6dc-7cdc88eff70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DEMO 4: COMPREHENSIVE LONG CONVERSATION - ALL FEATURES COMBINED\n",
      "================================================================================\n",
      "Starting comprehensive demo with 15-turn conversation...\n",
      "Manager settings: max_turns=8, max_words=200, periodic_summary every 4 runs\n",
      "\n",
      "\n",
      "================================================== TURN 1 ==================================================\n",
      "Adding: User: Hi! I'm Niharika, a CSE student from Guntur. I need help wit...\n",
      "\n",
      " Current Conversation State:\n",
      "User: Hi! I'm Niharika, a CSE student from Guntur. I need help with my final year project.\n",
      "\n",
      " Stats: 1 turns | 16 words | Run #1\n",
      "\n",
      "================================================== TURN 2 ==================================================\n",
      "Adding: Assistant: Hello Niharika! I'd be happy to help with your final year pr...\n",
      "\n",
      " Current Conversation State:\n",
      "User: Hi! I'm Niharika, a CSE student from Guntur. I need help with my final year project.\n",
      "Assistant: Hello Niharika! I'd be happy to help with your final year project. What area are you focusing on?\n",
      "\n",
      " Stats: 2 turns | 34 words | Run #2\n",
      "\n",
      "================================================== TURN 3 ==================================================\n",
      "Adding: User: I'm thinking about machine learning, specifically natural la...\n",
      "\n",
      " Current Conversation State:\n",
      "User: Hi! I'm Niharika, a CSE student from Guntur. I need help with my final year project.\n",
      "Assistant: Hello Niharika! I'd be happy to help with your final year project. What area are you focusing on?\n",
      "User: I'm thinking about machine learning, specifically natural language processing for sentiment analysis.\n",
      "\n",
      " Stats: 3 turns | 46 words | Run #3\n",
      "\n",
      "================================================== TURN 4 ==================================================\n",
      "Adding: Assistant: That's a great choice! Sentiment analysis is very practical....\n",
      "\n",
      "ðŸ”„ TRIGGERING PERIODIC SUMMARIZATION (Run #4)\n",
      "\n",
      " Current Conversation State:\n",
      "System: Previous conversation summary: There is no conversation to summarize yet. Let's start fresh. \n",
      "\n",
      "Here's a summary of our conversation so far:\n",
      "\n",
      "Niharika, a CSE student from Guntur, is seeking help with her final year project on machine learning, specifically natural language processing for sentiment analysis. She is considering working with social media data like tweets or reviews.\n",
      "User: I'm thinking about machine learning, specifically natural language processing for sentiment analysis.\n",
      "Assistant: That's a great choice! Sentiment analysis is very practical. Are you planning to work with social media data like tweets or reviews?\n",
      "\n",
      " Stats: 3 turns | 91 words | Run #4\n",
      "\n",
      "================================================== TURN 5 ==================================================\n",
      "Adding: User: Yes, I want to analyze movie reviews from IMDB. But I'm conf...\n",
      "\n",
      " Current Conversation State:\n",
      "System: Previous conversation summary: There is no conversation to summarize yet. Let's start fresh. \n",
      "\n",
      "Here's a summary of our conversation so far:\n",
      "\n",
      "Niharika, a CSE student from Guntur, is seeking help with her final year project on machine learning, specifically natural language processing for sentiment analysis. She is considering working with social media data like tweets or reviews.\n",
      "User: I'm thinking about machine learning, specifically natural language processing for sentiment analysis.\n",
      "Assistant: That's a great choice! Sentiment analysis is very practical. Are you planning to work with social media data like tweets or reviews?\n",
      "User: Yes, I want to analyze movie reviews from IMDB. But I'm confused about which algorithm to use.\n",
      "\n",
      " Stats: 4 turns | 108 words | Run #5\n",
      "\n",
      "================================================== TURN 6 ==================================================\n",
      "Adding: Assistant: For movie reviews, you could start with traditional methods ...\n",
      "\n",
      " Current Conversation State:\n",
      "System: Previous conversation summary: There is no conversation to summarize yet. Let's start fresh. \n",
      "\n",
      "Here's a summary of our conversation so far:\n",
      "\n",
      "Niharika, a CSE student from Guntur, is seeking help with her final year project on machine learning, specifically natural language processing for sentiment analysis. She is considering working with social media data like tweets or reviews.\n",
      "User: I'm thinking about machine learning, specifically natural language processing for sentiment analysis.\n",
      "Assistant: That's a great choice! Sentiment analysis is very practical. Are you planning to work with social media data like tweets or reviews?\n",
      "User: Yes, I want to analyze movie reviews from IMDB. But I'm confused about which algorithm to use.\n",
      "Assistant: For movie reviews, you could start with traditional methods like Naive Bayes or SVM, then try deep learning approaches like LSTM or BERT.\n",
      "\n",
      " Stats: 5 turns | 131 words | Run #6\n",
      "\n",
      "================================================== TURN 7 ==================================================\n",
      "Adding: User: I've heard about BERT but it seems complex. Is it worth the ...\n",
      "\n",
      " Current Conversation State:\n",
      "System: Previous conversation summary: There is no conversation to summarize yet. Let's start fresh. \n",
      "\n",
      "Here's a summary of our conversation so far:\n",
      "\n",
      "Niharika, a CSE student from Guntur, is seeking help with her final year project on machine learning, specifically natural language processing for sentiment analysis. She is considering working with social media data like tweets or reviews.\n",
      "User: I'm thinking about machine learning, specifically natural language processing for sentiment analysis.\n",
      "Assistant: That's a great choice! Sentiment analysis is very practical. Are you planning to work with social media data like tweets or reviews?\n",
      "User: Yes, I want to analyze movie reviews from IMDB. But I'm confused about which algorithm to use.\n",
      "Assistant: For movie reviews, you could start with traditional methods like Naive Bayes or SVM, then try deep learning approaches like LSTM or BERT.\n",
      "User: I've heard about BERT but it seems complex. Is it worth the effort for a final year project?\n",
      "\n",
      " Stats: 6 turns | 149 words | Run #7\n",
      "\n",
      "================================================== TURN 8 ==================================================\n",
      "Adding: Assistant: BERT can be complex to implement from scratch, but using pre...\n",
      "\n",
      "ðŸ”„ TRIGGERING PERIODIC SUMMARIZATION (Run #8)\n",
      "\n",
      " Current Conversation State:\n",
      "System: Previous conversation summary: There is no conversation to summarize yet. Let's start fresh. \n",
      "\n",
      "Here's a summary of our conversation so far:\n",
      "\n",
      "We started a conversation about Niharika's final year project on machine learning, specifically natural language processing for sentiment analysis using social media data like tweets or reviews. She is considering analyzing movie reviews from IMDB and we discussed possible algorithms to use, including traditional methods and deep learning approaches like BERT.\n",
      "User: I've heard about BERT but it seems complex. Is it worth the effort for a final year project?\n",
      "Assistant: BERT can be complex to implement from scratch, but using pre-trained models with libraries like Transformers makes it much easier and gives better results.\n",
      "\n",
      " Stats: 3 turns | 114 words | Run #8\n",
      "\n",
      "================================================== TURN 9 ==================================================\n",
      "Adding: User: That sounds good. What about the dataset size? How much data...\n",
      "\n",
      " Current Conversation State:\n",
      "System: Previous conversation summary: There is no conversation to summarize yet. Let's start fresh. \n",
      "\n",
      "Here's a summary of our conversation so far:\n",
      "\n",
      "We started a conversation about Niharika's final year project on machine learning, specifically natural language processing for sentiment analysis using social media data like tweets or reviews. She is considering analyzing movie reviews from IMDB and we discussed possible algorithms to use, including traditional methods and deep learning approaches like BERT.\n",
      "User: I've heard about BERT but it seems complex. Is it worth the effort for a final year project?\n",
      "Assistant: BERT can be complex to implement from scratch, but using pre-trained models with libraries like Transformers makes it much easier and gives better results.\n",
      "User: That sounds good. What about the dataset size? How much data do I need for training?\n",
      "\n",
      " Stats: 4 turns | 130 words | Run #9\n",
      "\n",
      "================================================== TURN 10 ==================================================\n",
      "Adding: Assistant: For a good sentiment analysis model, you'd typically want at...\n",
      "\n",
      " Current Conversation State:\n",
      "System: Previous conversation summary: There is no conversation to summarize yet. Let's start fresh. \n",
      "\n",
      "Here's a summary of our conversation so far:\n",
      "\n",
      "We started a conversation about Niharika's final year project on machine learning, specifically natural language processing for sentiment analysis using social media data like tweets or reviews. She is considering analyzing movie reviews from IMDB and we discussed possible algorithms to use, including traditional methods and deep learning approaches like BERT.\n",
      "User: I've heard about BERT but it seems complex. Is it worth the effort for a final year project?\n",
      "Assistant: BERT can be complex to implement from scratch, but using pre-trained models with libraries like Transformers makes it much easier and gives better results.\n",
      "User: That sounds good. What about the dataset size? How much data do I need for training?\n",
      "Assistant: For a good sentiment analysis model, you'd typically want at least 10,000-50,000 labeled reviews. IMDB dataset has 50k reviews which is perfect.\n",
      "\n",
      " Stats: 5 turns | 152 words | Run #10\n",
      "\n",
      "================================================== TURN 11 ==================================================\n",
      "Adding: User: Perfect! What programming tools should I use? I know Python ...\n",
      "\n",
      " Current Conversation State:\n",
      "System: Previous conversation summary: There is no conversation to summarize yet. Let's start fresh. \n",
      "\n",
      "Here's a summary of our conversation so far:\n",
      "\n",
      "We started a conversation about Niharika's final year project on machine learning, specifically natural language processing for sentiment analysis using social media data like tweets or reviews. She is considering analyzing movie reviews from IMDB and we discussed possible algorithms to use, including traditional methods and deep learning approaches like BERT.\n",
      "User: I've heard about BERT but it seems complex. Is it worth the effort for a final year project?\n",
      "Assistant: BERT can be complex to implement from scratch, but using pre-trained models with libraries like Transformers makes it much easier and gives better results.\n",
      "User: That sounds good. What about the dataset size? How much data do I need for training?\n",
      "Assistant: For a good sentiment analysis model, you'd typically want at least 10,000-50,000 labeled reviews. IMDB dataset has 50k reviews which is perfect.\n",
      "User: Perfect! What programming tools should I use? I know Python basics.\n",
      "\n",
      " Stats: 6 turns | 163 words | Run #11\n",
      "\n",
      "================================================== TURN 12 ==================================================\n",
      "Adding: Assistant: Great! You'll need Python with libraries like pandas for dat...\n",
      "\n",
      "ðŸ”„ TRIGGERING PERIODIC SUMMARIZATION (Run #12)\n",
      "\n",
      " Current Conversation State:\n",
      "System: Previous conversation summary: Here's a concise summary of our conversation so far:\n",
      "\n",
      "We discussed Niharika's final year project on sentiment analysis using machine learning and natural language processing. We considered using BERT with pre-trained models and the IMDB dataset, which has 50,000 reviews. We also outlined the necessary programming tools, including Python, pandas, scikit-learn, and transformers/pytorch.\n",
      "User: Perfect! What programming tools should I use? I know Python basics.\n",
      "Assistant: Great! You'll need Python with libraries like pandas for data handling, scikit-learn for traditional ML, and transformers/pytorch for BERT implementation.\n",
      "\n",
      " Stats: 3 turns | 87 words | Run #12\n",
      "\n",
      "================================================== TURN 13 ==================================================\n",
      "Adding: User: How long do you think this project will take? I have about 3...\n",
      "\n",
      " Current Conversation State:\n",
      "System: Previous conversation summary: Here's a concise summary of our conversation so far:\n",
      "\n",
      "We discussed Niharika's final year project on sentiment analysis using machine learning and natural language processing. We considered using BERT with pre-trained models and the IMDB dataset, which has 50,000 reviews. We also outlined the necessary programming tools, including Python, pandas, scikit-learn, and transformers/pytorch.\n",
      "User: Perfect! What programming tools should I use? I know Python basics.\n",
      "Assistant: Great! You'll need Python with libraries like pandas for data handling, scikit-learn for traditional ML, and transformers/pytorch for BERT implementation.\n",
      "User: How long do you think this project will take? I have about 3 months.\n",
      "\n",
      " Stats: 4 turns | 101 words | Run #13\n",
      "\n",
      "================================================== TURN 14 ==================================================\n",
      "Adding: Assistant: 3 months is plenty! You can spend 2-3 weeks on data preproce...\n",
      "\n",
      " Current Conversation State:\n",
      "System: Previous conversation summary: Here's a concise summary of our conversation so far:\n",
      "\n",
      "We discussed Niharika's final year project on sentiment analysis using machine learning and natural language processing. We considered using BERT with pre-trained models and the IMDB dataset, which has 50,000 reviews. We also outlined the necessary programming tools, including Python, pandas, scikit-learn, and transformers/pytorch.\n",
      "User: Perfect! What programming tools should I use? I know Python basics.\n",
      "Assistant: Great! You'll need Python with libraries like pandas for data handling, scikit-learn for traditional ML, and transformers/pytorch for BERT implementation.\n",
      "User: How long do you think this project will take? I have about 3 months.\n",
      "Assistant: 3 months is plenty! You can spend 2-3 weeks on data preprocessing, 1 month on model development and training, and remaining time on evaluation and documentation.\n",
      "\n",
      " Stats: 5 turns | 127 words | Run #14\n",
      "\n",
      "================================================== TURN 15 ==================================================\n",
      "Adding: User: This is really helpful! Can you suggest a timeline breakdown...\n",
      "\n",
      " Current Conversation State:\n",
      "System: Previous conversation summary: Here's a concise summary of our conversation so far:\n",
      "\n",
      "We discussed Niharika's final year project on sentiment analysis using machine learning and natural language processing. We considered using BERT with pre-trained models and the IMDB dataset, which has 50,000 reviews. We also outlined the necessary programming tools, including Python, pandas, scikit-learn, and transformers/pytorch.\n",
      "User: Perfect! What programming tools should I use? I know Python basics.\n",
      "Assistant: Great! You'll need Python with libraries like pandas for data handling, scikit-learn for traditional ML, and transformers/pytorch for BERT implementation.\n",
      "User: How long do you think this project will take? I have about 3 months.\n",
      "Assistant: 3 months is plenty! You can spend 2-3 weeks on data preprocessing, 1 month on model development and training, and remaining time on evaluation and documentation.\n",
      "User: This is really helpful! Can you suggest a timeline breakdown for better planning?\n",
      "\n",
      " Stats: 6 turns | 140 words | Run #15\n",
      "\n",
      "================================================== TURN 16 ==================================================\n",
      "Adding: Assistant: Sure! Week 1-2: Data collection and preprocessing. Week 3-6:...\n",
      "\n",
      "ðŸ”„ TRIGGERING PERIODIC SUMMARIZATION (Run #16)\n",
      "\n",
      " Current Conversation State:\n",
      "System: Previous conversation summary: There is no conversation to summarize. This appears to be a pre-existing conversation summary.\n",
      "User: This is really helpful! Can you suggest a timeline breakdown for better planning?\n",
      "Assistant: Sure! Week 1-2: Data collection and preprocessing. Week 3-6: Traditional ML models and BERT implementation. Week 7-10: Model comparison and optimization. Week 11-12: Documentation and presentation preparation.\n",
      "\n",
      " Stats: 3 turns | 57 words | Run #16\n",
      "\n",
      "================================================================================\n",
      "FINAL CONVERSATION STATE AFTER ALL 15 TURNS:\n",
      "================================================================================\n",
      "System: Previous conversation summary: There is no conversation to summarize. This appears to be a pre-existing conversation summary.\n",
      "User: This is really helpful! Can you suggest a timeline breakdown for better planning?\n",
      "Assistant: Sure! Week 1-2: Data collection and preprocessing. Week 3-6: Traditional ML models and BERT implementation. Week 7-10: Model comparison and optimization. Week 11-12: Documentation and presentation preparation.\n",
      "\n",
      "Final Stats: {'turns': 3, 'total_words': 57, 'run_count': 16}\n",
      "\n",
      "================================================================================\n",
      "TASK 1 DEMONSTRATION COMPLETE!\n",
      " Multiple conversation samples fed\n",
      " Turn-based truncation demonstrated\n",
      " Word-length truncation demonstrated\n",
      " Periodic summarization every k-th run shown\n",
      " All features working together in long conversation\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DEMO 4: COMPREHENSIVE LONG CONVERSATION - ALL FEATURES COMBINED\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create manager with combined constraints\n",
    "cm_final = ConversationManager(max_turns=8, max_words=200)\n",
    "\n",
    "# Realistic 15-turn conversation\n",
    "long_conversation = [\n",
    "    (\"user\", \"Hi! I'm Niharika, a CSE student from Guntur. I need help with my final year project.\"),\n",
    "    (\"assistant\", \"Hello Niharika! I'd be happy to help with your final year project. What area are you focusing on?\"),\n",
    "    (\"user\", \"I'm thinking about machine learning, specifically natural language processing for sentiment analysis.\"),\n",
    "    (\"assistant\", \"That's a great choice! Sentiment analysis is very practical. Are you planning to work with social media data like tweets or reviews?\"),\n",
    "    (\"user\", \"Yes, I want to analyze movie reviews from IMDB. But I'm confused about which algorithm to use.\"),\n",
    "    (\"assistant\", \"For movie reviews, you could start with traditional methods like Naive Bayes or SVM, then try deep learning approaches like LSTM or BERT.\"),\n",
    "    (\"user\", \"I've heard about BERT but it seems complex. Is it worth the effort for a final year project?\"),\n",
    "    (\"assistant\", \"BERT can be complex to implement from scratch, but using pre-trained models with libraries like Transformers makes it much easier and gives better results.\"),\n",
    "    (\"user\", \"That sounds good. What about the dataset size? How much data do I need for training?\"),\n",
    "    (\"assistant\", \"For a good sentiment analysis model, you'd typically want at least 10,000-50,000 labeled reviews. IMDB dataset has 50k reviews which is perfect.\"),\n",
    "    (\"user\", \"Perfect! What programming tools should I use? I know Python basics.\"),\n",
    "    (\"assistant\", \"Great! You'll need Python with libraries like pandas for data handling, scikit-learn for traditional ML, and transformers/pytorch for BERT implementation.\"),\n",
    "    (\"user\", \"How long do you think this project will take? I have about 3 months.\"),\n",
    "    (\"assistant\", \"3 months is plenty! You can spend 2-3 weeks on data preprocessing, 1 month on model development and training, and remaining time on evaluation and documentation.\"),\n",
    "    (\"user\", \"This is really helpful! Can you suggest a timeline breakdown for better planning?\"),\n",
    "    (\"assistant\", \"Sure! Week 1-2: Data collection and preprocessing. Week 3-6: Traditional ML models and BERT implementation. Week 7-10: Model comparison and optimization. Week 11-12: Documentation and presentation preparation.\")\n",
    "]\n",
    "\n",
    "print(\"Starting comprehensive demo with 15-turn conversation...\")\n",
    "print(\"Manager settings: max_turns=8, max_words=200, periodic_summary every 4 runs\\n\")\n",
    "\n",
    "for i, (role, msg) in enumerate(long_conversation, start=1):\n",
    "    print(f\"\\n{'='*50} TURN {i} {'='*50}\")\n",
    "    print(f\"Adding: {role.capitalize()}: {msg[:60]}{'...' if len(msg) > 60 else ''}\")\n",
    "    \n",
    "    cm_final.add_message(role, msg)\n",
    "    \n",
    "    # Periodic summarization every 4 runs\n",
    "    cm_final.periodic_summary(client, k=4)\n",
    "    \n",
    "    print(f\"\\n Current Conversation State:\")\n",
    "    print(cm_final.get_readable_history())\n",
    "    \n",
    "    stats = cm_final.get_stats()\n",
    "    print(f\"\\n Stats: {stats['turns']} turns | {stats['total_words']} words | Run #{stats['run_count']}\")\n",
    "    \n",
    "    # Show truncation effects\n",
    "    if stats['turns'] == 8:\n",
    "        print(\"  TURN LIMIT REACHED - Older messages will be truncated\")\n",
    "    if stats['total_words'] >= 180:\n",
    "        print(\"  APPROACHING WORD LIMIT - May trigger word truncation\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL CONVERSATION STATE AFTER ALL 15 TURNS:\")\n",
    "print(\"=\"*80)\n",
    "print(cm_final.get_readable_history())\n",
    "print(f\"\\nFinal Stats: {cm_final.get_stats()}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TASK 1 DEMONSTRATION COMPLETE!\")\n",
    "print(\" Multiple conversation samples fed\")\n",
    "print(\" Turn-based truncation demonstrated\")\n",
    "print(\" Word-length truncation demonstrated\") \n",
    "print(\" Periodic summarization every k-th run shown\")\n",
    "print(\" All features working together in long conversation\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
